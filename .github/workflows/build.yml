name: Build
on:
  pull_request:
  push:
    branches:
      - main
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  check-version:
    runs-on: ubuntu-latest
    outputs:
      llama-tag: ${{ steps.tags.outputs.llama-tag }}
      current-tag: ${{ steps.tags.outputs.current-tag }}
    steps:
      - name: Check out the repo
        uses: actions/checkout@v5
      - name: Checkout llama.cpp repo
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          path: llama.cpp
          fetch-tags: 'true'
      - name: Fetch llama tags
        run: |
          cd llama.cpp
          git fetch --prune --prune-tags --depth=1 --no-recurse-submodules
      - name: Determine llama.cpp tag name
        id: llamatag
        uses: ./.github/actions/get-tag-name
        with:
          repo-path: ./llama.cpp
      - name: Fetch tags
        run: |
          git fetch --prune --prune-tags --depth=1 --no-recurse-submodules
      - name: Determine own tag name
        id: currenttag
        uses: ./.github/actions/get-tag-name
        with:
          repo-path: .
      - name: Save tags
        id: tags
        run: |
          echo "llama-tag=${{ steps.llamatag.outputs.name }}" >> "$GITHUB_OUTPUT"
          echo "current-tag=${{ steps.currenttag.outputs.name }}" >> "$GITHUB_OUTPUT"

  build-cuda:
    needs: check-version
    if: ${{ needs.check-version.outputs.llama-tag != needs.check-version.outputs.current-tag }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout llama.cpp repo
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          path: llama.cpp
          fetch-tags: 'true'
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Build amd64
        run: |
          docker pull --platform linux/amd64 ghcr.io/hybridgroup/llama-cpp-builder-cuda-12.9:latest
          docker run --rm -v $(pwd):/src -a stdout -a stderr --platform linux/amd64 --entrypoint="/src/builder.sh" ghcr.io/hybridgroup/llama-cpp-builder-cuda-12.9:latest
      - name: Compress release binaries
        run: |
          zip -j llama-${{ needs.check-version.outputs.llama-tag }}-bin-ubuntu-cuda-x64.zip llama.cpp/build/bin/*
      - name: Create release
        uses: ncipollo/release-action@v1
        with:
          artifacts: llama-${{ needs.check-version.outputs.llama-tag }}-bin-ubuntu-cuda-x64.zip
          tag: ${{ needs.check-version.outputs.llama-tag }}
          commit: main
