name: Build
on:
  pull_request:
  push:
    branches:
      - main
  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-cuda:
    runs-on: ubuntu-latest
    steps:
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Check out the repo
        uses: actions/checkout@v5
      - name: Checkout llama.cpp repo
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          path: llama.cpp
          fetch-tags: 'true'
      - name: Determine tag name
        id: tag
        uses: ./.github/actions/get-tag-name
        with:
          repo-path: ./llama.cpp
      - name: Build amd64
        run: |
          docker pull --platform linux/amd64 ghcr.io/hybridgroup/llama-cpp-builder-cuda-12.9:latest
          docker run --rm -v $(pwd):/src -a stdout -a stderr --platform linux/amd64 ghcr.io/hybridgroup/llama-cpp-builder-cuda-12.9:latest
      - name: Archive llama.cpp libraries
        uses: actions/upload-artifact@v4
        with:
            name: llama-${{ steps.tag.outputs.name }}-bin-ubuntu-cuda-x64
            path: llama.cpp/build/bin
