name: Build
on:
  pull_request:
  push:
    branches:
      - main
  workflow_dispatch:
  schedule:
    - cron: '15 * * * *'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  check-version:
    runs-on: ubuntu-latest
    outputs:
      llama-tag: ${{ steps.tags.outputs.llama-tag }}
      current-tag: ${{ steps.tags.outputs.current-tag }}
    steps:
      - name: Check out the repo
        uses: actions/checkout@v5
      - name: Checkout llama.cpp repo
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          path: llama.cpp
          fetch-tags: 'true'
      - name: Fetch llama tags
        run: |
          cd llama.cpp
          git fetch --prune --prune-tags --unshallow --no-recurse-submodules
      - name: Determine llama.cpp tag name
        id: llamatag
        uses: ./.github/actions/get-tag-name
        with:
          repo-path: ./llama.cpp
      - name: Fetch tags
        run: |
          git fetch --prune --prune-tags --unshallow --no-recurse-submodules
      - name: Determine own tag name
        id: currenttag
        uses: ./.github/actions/get-tag-name
        with:
          repo-path: .
      - name: Save tags
        id: tags
        run: |
          echo "llama-tag=${{ steps.llamatag.outputs.name }}" >> "$GITHUB_OUTPUT"
          echo "current-tag=${{ steps.currenttag.outputs.name }}" >> "$GITHUB_OUTPUT"

  build-cuda-amd64:
    needs: check-version
    if: ${{ needs.check-version.outputs.llama-tag != needs.check-version.outputs.current-tag }}
    runs-on: ubuntu-latest
    container:
      image: nvidia/cuda:12.9.1-devel-ubuntu24.04
      options: --platform linux/amd64
    steps:
      - name: Check out the repo
        uses: actions/checkout@v5
      - name: Checkout llama.cpp repo
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          path: llama.cpp
          ref: ${{ needs.check-version.outputs.llama-tag }}
          fetch-tags: 'true'
      - name: Install dependencies
        env:
          DEBIAN_FRONTEND: noninteractive
        run: |
            apt update
            apt install -y cmake build-essential ninja-build libgomp1 git libssl-dev libcurl4-openssl-dev zip
      - name: Build amd64
        working-directory: llama.cpp
        run: |
          cmake -S . -B build -G Ninja \
            -DCMAKE_EXE_LINKER_FLAGS="-Wl,--allow-shlib-undefined" \
            -DCMAKE_CUDA_ARCHITECTURES="86;89" \
            -DGGML_CPU_ALL_VARIANTS=ON \
            -DGGML_CUDA=ON \
            -DGGML_BACKEND_DL=ON
          cmake --build build --config Release -j $(nproc)
      - name: Upload release binaries
        uses: actions/upload-artifact@v5
        with:
          path: llama.cpp/build/bin/*
          name: llama-${{ needs.check-version.outputs.llama-tag }}-bin-ubuntu-cuda-x64.zip

  build-cuda-arm64:
    needs: check-version
    if: ${{ needs.check-version.outputs.llama-tag != needs.check-version.outputs.current-tag }}
    runs-on: ubuntu-22.04-arm
    container: 
      image: nvidia/cuda:12.9.1-devel-ubuntu22.04
      options: --platform linux/arm64
    steps:
      - name: Check out the repo
        uses: actions/checkout@v5
      - name: Checkout llama.cpp repo
        uses: actions/checkout@v5
        with:
          repository: ggml-org/llama.cpp
          path: llama.cpp
          ref: ${{ needs.check-version.outputs.llama-tag }}
          fetch-tags: 'true'
      - name: Install dependencies
        env:
          DEBIAN_FRONTEND: noninteractive
        run: |
            apt update
            apt install -y cmake build-essential ninja-build libgomp1 git libssl-dev libcurl4-openssl-dev zip
      - name: Build arm64
        working-directory: llama.cpp
        run: |
          cmake -S . -B build -G Ninja \
            -DCMAKE_EXE_LINKER_FLAGS="-Wl,--allow-shlib-undefined" \
            -DCMAKE_CUDA_ARCHITECTURES="87" \
            -DGGML_CPU_ALL_VARIANTS=ON \
            -DGGML_CUDA=ON \
            -DGGML_BACKEND_DL=ON
          cmake --build build --config Release -j $(nproc)
      - name: Upload release binaries
        uses: actions/upload-artifact@v5
        with:
          path: llama.cpp/build/bin/*
          name: llama-${{ needs.check-version.outputs.llama-tag }}-bin-ubuntu-cuda-arm64.zip

  release:
    needs: 
      - check-version
      - build-cuda-amd64
      - build-cuda-arm64
    runs-on: ubuntu-latest
    steps:
      - name: Check out the repo
        uses: actions/checkout@v5
      - name: Download amd64 artifact
        uses: actions/download-artifact@v6
        with:
          name: llama-${{ needs.check-version.outputs.llama-tag }}-bin-ubuntu-cuda-x64.zip
      - name: Download arm64 artifact
        uses: actions/download-artifact@v6
        with:
          name: llama-${{ needs.check-version.outputs.llama-tag }}-bin-ubuntu-cuda-arm64.zip
      - name: Create final release
        uses: ncipollo/release-action@v1
        with:
          tag: ${{ needs.check-version.outputs.llama-tag }}
          commit: main
          body: |
            ## Changes in llama.cpp ${{ needs.check-version.outputs.llama-tag }}
            See the [llama.cpp releases](https://github.com/ggml-org/llama.cpp/releases/tag/${{ needs.check-version.outputs.llama-tag }}) for details.
          artifacts: "llama-*.zip"

  trigger-yzma-tests:
    needs: release
    runs-on: ubuntu-latest
    steps:
      - name: Trigger yzma repo Linux build
        run: |
          curl -X POST \
          -H "Authorization: Bearer ${{secrets.YZMA_BUILD_ACCESS}}" \
          -H "Accept: application/vnd.github.v3+json" \
          https://api.github.com/repos/hybridgroup/yzma/actions/workflows/linux.yml/dispatches \
          -d '{"ref": "main"}'
      - name: Trigger yzma repo macOS build
        run: |
          curl -X POST \
          -H "Authorization: Bearer ${{secrets.YZMA_BUILD_ACCESS}}" \
          -H "Accept: application/vnd.github.v3+json" \
          https://api.github.com/repos/hybridgroup/yzma/actions/workflows/macos.yml/dispatches \
          -d '{"ref": "main"}'
      - name: Trigger yzma repo Windows build
        run: |
          curl -X POST \
          -H "Authorization: Bearer ${{secrets.YZMA_BUILD_ACCESS}}" \
          -H "Accept: application/vnd.github.v3+json" \
          https://api.github.com/repos/hybridgroup/yzma/actions/workflows/windows.yml/dispatches \
          -d '{"ref": "main"}'
